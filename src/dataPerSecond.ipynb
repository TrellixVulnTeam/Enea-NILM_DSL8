{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "def process(df,file_name,dir_path):\n",
    "    # estrazione delle colonne TIMESTAMP e POWER\n",
    "    df = df[['timestamp', 'power']]\n",
    "            \n",
    "    # conversione data dal formato unixtime\n",
    "    df['date'] = pd.to_datetime(df['timestamp'], unit='ms').dt.tz_localize(\"GMT\").dt.tz_convert('Europe/Rome')\n",
    "            \n",
    "    # arrotondamento dal ms al secondo pi√π vicino\n",
    "    df['date'] = df['date'].dt.round('1s')\n",
    "\n",
    "    df = df[['date', 'power']]\n",
    "            \n",
    "    # creazione time series settando la data come index\n",
    "    df = df.set_index('date')\n",
    "   \n",
    "    # osservazioni duplicate sul secondo: potenza sostituita con la media tra le 2 potenze\n",
    "    df = df.groupby('date').mean()\n",
    "          \n",
    "    # crea nel range delle date eventuali nuovi timestamp, in modo da avere timestamp ogni secondo\n",
    "    df = df.reindex(pd.date_range(start=df.index[0], end=df.index[-1], freq='1s'))\n",
    "\n",
    "    # sostituisce i valori NAN dei timestamp mancanti propagando l'ultimo valore disponibile\n",
    "    #df = df.fillna(method='ffill')\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df1 = pd.DataFrame(columns=['timestamp','power'])\n",
    "    df1['timestamp'] = df['index']\n",
    "    df1['power'] = df['power']    \n",
    "    \n",
    "    csv_dir = os.path.join(os.path.abspath('..'),'Dati al secondo_prova')        \n",
    "    if not os.path.exists(csv_dir):\n",
    "       os.mkdir(csv_dir)\n",
    "    dir_EB = os.path.join(csv_dir,dir_path)\n",
    "    if not os.path.exists(dir_EB):\n",
    "       os.mkdir(dir_EB)\n",
    "    df1.to_csv(os.path.join(dir_EB,file_name + \".csv\"),index=False)\n",
    "    \n",
    "    '''\n",
    "    plot_dir = os.path.join(os.path.abspath('..'),'plotPerSecond_Day_1_JAN')        \n",
    "    if not os.path.exists(plot_dir):\n",
    "       os.mkdir(plot_dir)\n",
    "    dir_EB = os.path.join(plot_dir,dir_path)\n",
    "    if not os.path.exists(dir_EB):\n",
    "        os.mkdir(dir_EB)\n",
    "    ax = df1.iloc[1:86400].plot()\n",
    "    path_plot = os.path.join(dir_EB,file_name + \".png\")\n",
    "    ax.set_title(file_name)\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(path_plot)\n",
    "    #plt.savefig(path_plot)\n",
    "    #plt.show()\n",
    "    '''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  import sys\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  # Remove the CWD from sys.path while we load stuff.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "PATH = '../Dati puntuali Smart Homes Gennaio-Giugno 2019'\n",
    "#PATH = '../Dati puntuali Smart HOME'\n",
    "#PATH ='../datasetProva'\n",
    "\n",
    "\n",
    "for r,dir,f in os.walk(PATH):\n",
    "    for d in dir:\n",
    "        DIR_PATH = d\n",
    "        p = os.path.join(r,DIR_PATH)\n",
    "        for r1,d1,f1 in os.walk(p):\n",
    "            for file in f1 :\n",
    "                chunksize = 50000\n",
    "                file_path = os.path.join(PATH,DIR_PATH,file)\n",
    "                df = pd.read_csv(file_path, sep=';', chunksize=chunksize, iterator=True)\n",
    "                df = pd.concat(df, ignore_index=True)\n",
    "                file_name = file.split('.')[0]\n",
    "                process(df,file_name,DIR_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e43341fc",
   "language": "python",
   "display_name": "PyCharm (TESI)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}